This repo contains a custom implementation of softmax regression (multiclass logistic regression) for the Digit Recognizer challenge on Kaggle.

Just to be clear, this isn’t the best-performing solution I’ve built. I’ve also written a Convolutional Neural Network that hits over 98% accuracy on MNIST.
But this one is all about clarity, structure, and simplicity. It's a fully manual softmax model that still gets around 90% accuracy, using nothing but NumPy and clean code. The implementation is modular and neat.

Note: The dataset files are too large to be included in the repo. You can download them from <a href="https://www.kaggle.com/competitions/digit-recognizer/data" target="_blank">Kaggle</a> and place them in a folder named data.
